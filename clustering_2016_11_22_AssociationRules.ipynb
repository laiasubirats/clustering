{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "(4414, 353)\n",
      "['entity_id', 'sampleType', 'FECHA_NACIMIENTO', 'MUNICIPIO_RESIDENCIA', 'MUNICIPIO_NACIMIENTO', 'PROVINCIA_RESIDENCIA', 'PAIS_NACIMIENTO', 'CALC_AVG_HEIGHT', 'CALC_AVG_PESO', 'CALC_AVG_CINTURA', 'CALC_AVG_CADERA']\n",
      "Enfermedades HTA 865\n",
      "df_2 (4414, 342)\n",
      "[45 46 47 48 58 59]\n",
      "df_3 (4414, 336)\n",
      "df_4 (4414, 336)\n",
      "data (4414, 336)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# In[110]:\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from time import time\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from operator import truediv\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "get_ipython().magic('matplotlib')\n",
    "\n",
    "\n",
    "# In[111]:\n",
    "\n",
    "df_all=pd.read_csv('C:/binary_2016_11_14.csv')\n",
    "#df=pd.read_csv('C:/binary_2016_11_14.csv')\n",
    "\n",
    "df_all = df_all[df_all['SEXO']==1]\n",
    "msk = np.random.rand(len(df_all)) < 0.8\n",
    "df, df_test = df_all[msk].copy(deep = True), df_all[~msk].copy(deep = True)\n",
    "df = df.reset_index()\n",
    "print(df.shape)\n",
    "\"\"\"\n",
    "msk = np.random.rand(len(df_all)) < 0.8\n",
    "\n",
    "df= df_all[msk]\n",
    "print(\"Longitud\",len(df))\n",
    "\n",
    "df_test = df_all[~msk]\n",
    "print(\"Longitud2\",len(df_test))\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# In[112]:\n",
    "\n",
    "to_del = ['entity_id','sampleType','FECHA_NACIMIENTO','MUNICIPIO_RESIDENCIA',\n",
    "          'MUNICIPIO_NACIMIENTO','PROVINCIA_RESIDENCIA','PAIS_NACIMIENTO', 'CALC_AVG_HEIGHT','CALC_AVG_PESO','CALC_AVG_CINTURA','CALC_AVG_CADERA' \n",
    "         ]\n",
    "\"\"\"\n",
    "to_del.extend(['ENFERMEDADES_DIABETES','ENFERMEDADES_HTA',\n",
    "              'ENFERMEDADES_HIPERCOLESTEROLEMIA','ENFERMEDADES_ICTUS',\n",
    "              'ENFERMEDADES_INFARTO','ENFERMEDADES_ANGINA'\n",
    "              ])\n",
    "\"\"\"\n",
    "\n",
    "print (to_del)\n",
    "print (\"Enfermedades HTA\",np.sum(df['ENFERMEDADES_HTA'] == 1))\n",
    "\n",
    "#Filter_selected cols\n",
    "filtered_cols = [c for c in df.columns if (c not in to_del) ]#and ('ENF' not in c)\n",
    "df_2 = df[filtered_cols]\n",
    "print (\"df_2\",df_2.shape)\n",
    "\n",
    "# Filter complete null columns\n",
    "cols = np.where((np.sum(df_2.isnull(), axis=0).values) == df_2.shape[0])[0]\n",
    "print (cols)\n",
    "filt_cols = [c for c in df_2.columns if c not in df_2.columns[cols]]\n",
    "df_3 = df_2[filt_cols]\n",
    "print (\"df_3\",df_3.shape)\n",
    "\n",
    "#Fill na\n",
    "df_4 = df_3.fillna(value=np.mean(df_3,axis=0),inplace=False,axis=0).values\n",
    "print (\"df_4\",df_4.shape)\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler().fit(df_4)\n",
    "data = scaler.transform(df_4)\n",
    "data2 = df_4\n",
    "print (\"data\",data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num pca_comps per > 0.8 ratio: 46 0.803501546849\n",
      "Explained variance first 2 components 0.144404473231\n",
      "336\n",
      "0.144404473231\n",
      "PCA+K-means: 46\n"
     ]
    }
   ],
   "source": [
    "#### Feat sel with pca(0.8, 0.9) explained var \n",
    "thrd = 0.8\n",
    "total = 0\n",
    "pca = PCA().fit(data)\n",
    "reduced_data = pca.transform(data)\n",
    "for pca_comps,r in enumerate(pca.explained_variance_ratio_):\n",
    "    if total > thrd:\n",
    "        break\n",
    "    total += r\n",
    "print (\"Num pca_comps per >\", thrd,\"ratio:\", pca_comps, total)\n",
    "print (\"Explained variance first 2 components\",pca.explained_variance_ratio_[0]+pca.explained_variance_ratio_[1])\n",
    "print (pca.n_components_)\n",
    "print (np.sum(pca.explained_variance_ratio_[:2]))\n",
    "\n",
    "print (\"PCA+K-means:\", pca_comps)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=2, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_clusters = 2\n",
    "pca = PCA().fit(data)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(len(pca.explained_variance_ratio_)), np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.axvline(pca_comps, color=\"red\")  \n",
    "plt.ylim(0.0,1.1)\n",
    "plt.show()\n",
    "\n",
    "reduced_data = pca.transform(data)\n",
    "#print (\"Reduced data: \",reduced_data.shape)\n",
    "kmeans = KMeans(init='k-means++', n_clusters=n_clusters, n_init=10)\n",
    "kmeans.fit(reduced_data[:,:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(4414, 336)\n",
      "<class 'numpy.ndarray'>\n",
      "1\n",
      "Example 0.0\n",
      "count 4414\n",
      "newarshape (4414, 6)\n",
      "Fila:      clusters        tipo        weight  age    sport         Diet\n",
      "0  clusters1  nodiabetes  normalweight  40s  nosport  DietAverage\n",
      "1  clusters0        sano         obese  50s      NaN  DietAverage\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nar1_ok=ar1.values.tolist()\\nprint(len(ar1_ok))\\nprint(type(ar1))\\nar2 = df[kmeans.labels_==1]\\nprint(ar2.shape)\\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar1 = df_3[kmeans.labels_==0]\n",
    "print(type(df_3))\n",
    "print(df_3.shape)\n",
    "print(type(kmeans.labels_))\n",
    "print(kmeans.labels_[0])\n",
    "count=0\n",
    "#newar = {'clusters': \"cluster9\"}\n",
    "print(\"Example\",df.loc[0,'ENFERMEDADES_DIABETES_T2DM'])\n",
    "newar = pd.DataFrame()\n",
    "for x in df_3.index: \n",
    "    #print(\"Count\",count)\n",
    "    newar.set_value(count,'clusters','{}{}'.format('clusters',kmeans.labels_[count]))\n",
    "    #newar.set_value(count,'diabetes','{}{}'.format('diabetes',df.loc[count,'ENFERMEDADES_DIABETES_T2DM']))\n",
    "    #newar.set_value(count,'HTA','{}{}'.format('HTA',df.loc[count,'ENFERMEDADES_HTA']))\n",
    "    #newar.set_value(count,'col','{}{}'.format('col',df.loc[count,'ENFERMEDADES_HIPERCOLESTEROLEMIA']))\n",
    "    #newar.set_value(count,'infarto','{}{}'.format('infarto',df.loc[count,'ENFERMEDADES_INFARTO']))\n",
    "    #newar.set_value(count,'angina','{}{}'.format('angina',df.loc[count,'ENFERMEDADES_ANGINA']))\n",
    "    #newar.set_value(count,'ictus','{}{}'.format('ictus',df.loc[count,'ENFERMEDADES_ICTUS']))\n",
    "    if (df.loc[count,'ENFERMEDADES_DIABETES_T2DM']==0 and df.loc[count,'ENFERMEDADES_HIPERCOLESTEROLEMIA']==0 and df.loc[count,'ENFERMEDADES_HTA']==0 and df.loc[count,'ENFERMEDADES_ICTUS']==0 and df.loc[count,'ENFERMEDADES_ANGINA']==0 and df.loc[count,'ENFERMEDADES_INFARTO']==0):newar.set_value(count,'tipo','sano')\n",
    "    else:\n",
    "        if (df.loc[count,'ENFERMEDADES_DIABETES_T2DM']==0): newar.set_value(count,'tipo','nodiabetes')\n",
    "        else:\n",
    "            if (df.loc[count,'ENFERMEDADES_DIABETES_T2DM']==1 and df.loc[count,'ENFERMEDADES_HIPERCOLESTEROLEMIA']==0 and df.loc[count,'ENFERMEDADES_HTA']==0 and df.loc[count,'ENFERMEDADES_ICTUS']==0 and df.loc[count,'ENFERMEDADES_ANGINA']==0 and df.loc[count,'ENFERMEDADES_INFARTO']==0):newar.set_value(count,'tipo','diabetes')\n",
    "            else:newar.set_value(count,'tipo','diabetescomplejo')\n",
    "\n",
    "    if(df.loc[count,'BMI']<18.5): newar.set_value(count,'weight','underweight')\n",
    "    else:\n",
    "        if(df.loc[count,'BMI']<24.9): newar.set_value(count,'weight','normalweight')\n",
    "        else:\n",
    "            if (df.loc[count,'BMI']<29.9): newar.set_value(count,'weight','overweight')\n",
    "            else:\n",
    "                if (df.loc[count,'BMI']>29.8): newar.set_value(count,'weight','obese')\n",
    "    if(df.loc[count,'EDAD_ANOS']<50): newar.set_value(count,'age','40s')\n",
    "    else:\n",
    "        if(df.loc[count,'EDAD_ANOS']<60): newar.set_value(count,'age','50s')\n",
    "        else:\n",
    "            if (df.loc[count,'EDAD_ANOS']<70): newar.set_value(count,'age','60s')\n",
    "    if(df.loc[count,'ACTIVIDAD_FISICA_LIBRE_DEPORTE_REGULAR_0']==1): newar.set_value(count,'sport','sport')\n",
    "    if(df.loc[count,'ACTIVIDAD_FISICA_LIBRE_DEPORTE_REGULAR_1']==1): newar.set_value(count,'sport','nosport')\n",
    "    if(df.loc[count,'PREDIMED_SCORE']<5): newar.set_value(count,'Diet','DietVeryLow')\n",
    "    else:\n",
    "        if(df.loc[count,'PREDIMED_SCORE']<8): newar.set_value(count,'Diet','DietLow')\n",
    "        else:\n",
    "            if (df.loc[count,'PREDIMED_SCORE']<11): newar.set_value(count,'Diet','DietAverage')\n",
    "            else:\n",
    "                newar.set_value(count,'Diet','DietHigh') \n",
    "    #newar[count,'diabetes']='{}{}'.format('diabetes',df.loc[count,'ENFERMEDADES_DIABETES_T2DM'])\n",
    "    #print(\"newwar\",newar[count,'clusters'])\n",
    "    count=count+1\n",
    "#newar2  = pd.Series(newar,index=newar.keys())\n",
    "print(\"count\",count)\n",
    "print(\"newarshape\",newar.shape)\n",
    "print(\"Fila: \",newar.head(2))\n",
    "newar_ok=newar.values.tolist()\n",
    "newar_ok_copy=newar_ok\n",
    "\"\"\"\n",
    "ar1_ok=ar1.values.tolist()\n",
    "print(len(ar1_ok))\n",
    "print(type(ar1))\n",
    "ar2 = df[kmeans.labels_==1]\n",
    "print(ar2.shape)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['clusters1', 'nodiabetes', 'normalweight', '40s', 'nosport', 'DietAverage'], ['clusters0', 'sano', 'obese', '50s', 'DietAverage'], ['clusters1', 'diabetescomplejo', 'obese', '40s', 'nosport', 'DietAverage'], ['clusters1', 'diabetescomplejo', 'overweight', '50s', 'DietLow'], ['clusters1', 'diabetescomplejo', 'overweight', '40s', 'nosport', 'DietAverage']]\n",
      "Longitud inicial:  4414\n",
      "** [['clusters1', 'nodiabetes', 'normalweight', '40s', 'nosport', 'DietAverage'], ['clusters0', 'sano', 'obese', '50s', 'DietAverage'], ['clusters1', 'diabetescomplejo', 'obese', '40s', 'nosport', 'DietAverage'], ['clusters1', 'diabetescomplejo', 'overweight', '50s', 'DietLow'], ['clusters1', 'diabetescomplejo', 'overweight', '40s', 'nosport', 'DietAverage']]\n",
      "Longitud final:  4414\n"
     ]
    }
   ],
   "source": [
    "print(newar_ok[0:5])\n",
    "print(\"Longitud inicial: \",len(newar_ok))\n",
    "for x in range(len(newar_ok)): \n",
    "    #print(\"X\", x, \",\",newar_ok[x])\n",
    "    astring=newar_ok[x]\n",
    "    y=0\n",
    "    for y in range(len(astring),0,-1):\n",
    "        #print(\"y\",y-1,\":\",astring[y-1])\n",
    "        if(str(astring[y-1]).endswith('nan')):\n",
    "            newar_ok[x].remove(astring[y-1])\n",
    "            #print(\"Removed\",newar_ok[x])\n",
    "    #if(len(newar_ok[x])==1):\n",
    "    #print(\"Final: \", x, \",\",newar_ok[x])\n",
    "\n",
    "        #newar_ok=remove_element(newar_ok,x)\n",
    "    #print(newar_ok[x])    \n",
    "    #if (newar_ok[x].endswith('nan')):\n",
    "        #newar_ok.pop(x)\n",
    "    #print(\"Final2: \", x, \",\",newar_ok[x])\n",
    "    \n",
    "for x in range (len(newar_ok),0,-1):\n",
    "    if(len(newar_ok[x-1])==1):\n",
    "        #print('hola')\n",
    "        del newar_ok[x-1]\n",
    "    \n",
    "print(\"**\",newar_ok[0:5])\n",
    "print(\"Longitud final: \",len(newar_ok))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Association rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    \"Load the sample dataset.\"\n",
    "    return [[1, 3, 4], [2, 3, 5], [1, 2, 3, 5], [2, 5]]\n",
    "\n",
    "\n",
    "def createC1(dataset):\n",
    "    \"Create a list of candidate item sets of size one.\"\n",
    "    c1 = []\n",
    "    for transaction in dataset:\n",
    "        for item in transaction:\n",
    "            if not [item] in c1:\n",
    "                c1.append([item])\n",
    "    c1.sort()\n",
    "    #frozenset because it will be a ket of a dictionary.\n",
    "    return list(map(frozenset, c1))\n",
    "\n",
    "\n",
    "def scanD(dataset, candidates, min_support):\n",
    "    \"Returns all candidates that meets a minimum support level\"\n",
    "    #print(\"longitud\",len(list(dataset)))\n",
    "    sscnt = {}\n",
    "    for tid in dataset:\n",
    "        for can in candidates:\n",
    "            if can.issubset(tid):\n",
    "                sscnt.setdefault(can, 0)\n",
    "                sscnt[can] += 1\n",
    "\n",
    "    num_items = float(len(list(dataset)))\n",
    "    retlist = []\n",
    "    support_data = {}\n",
    "    for key in sscnt:\n",
    "        support = sscnt[key] / num_items\n",
    "        if support >= min_support:\n",
    "            retlist.insert(0, key)\n",
    "        support_data[key] = support\n",
    "    return retlist, support_data\n",
    "\n",
    "\n",
    "def aprioriGen(freq_sets, k):\n",
    "    \"Generate the joint transactions from candidate sets\"\n",
    "    retList = []\n",
    "    lenLk = len(freq_sets)\n",
    "    for i in range(lenLk):\n",
    "        for j in range(i + 1, lenLk):\n",
    "            L1 = list(freq_sets[i])[:k - 2]\n",
    "            L2 = list(freq_sets[j])[:k - 2]\n",
    "            L1.sort()\n",
    "            L2.sort()\n",
    "            if L1 == L2:\n",
    "                retList.append(freq_sets[i] | freq_sets[j])\n",
    "    return retList\n",
    "\n",
    "\n",
    "def apriori(dataset, minsupport=0.5):\n",
    "    \"Generate a list of candidate item sets\"\n",
    "    C1 = createC1(dataset)\n",
    "    D = list(map(set, dataset))\n",
    "    L1, support_data = scanD(D, C1, minsupport)\n",
    "    L = [L1]\n",
    "    k = 2\n",
    "    while (len(L[k - 2]) > 0):\n",
    "        Ck = aprioriGen(L[k - 2], k)\n",
    "        Lk, supK = scanD(D, Ck, minsupport)\n",
    "        support_data.update(supK)\n",
    "        L.append(Lk)\n",
    "        k += 1\n",
    "\n",
    "    return L, support_data\n",
    "\n",
    "def generateRules(L, support_data, min_confidence=0.7):\n",
    "    \"\"\"Create the association rules\n",
    "    L: list of frequent item sets\n",
    "    support_data: support data for those itemsets\n",
    "    min_confidence: minimum confidence threshold\n",
    "    \"\"\"\n",
    "    rules = []\n",
    "    for i in range(1, len(L)):\n",
    "        for freqSet in L[i]:\n",
    "            H1 = [frozenset([item]) for item in freqSet]\n",
    "            #print (\"freqSet\", freqSet, 'H1', H1)\n",
    "            if (i > 1):\n",
    "                rules_from_conseq(freqSet, H1, support_data, rules, min_confidence)\n",
    "            else:\n",
    "                calc_confidence(freqSet, H1, support_data, rules, min_confidence)\n",
    "    return rules\n",
    "\n",
    "\n",
    "def calc_confidence(freqSet, H, support_data, rules, min_confidence=0.7):\n",
    "    \"Evaluate the rule generated\"\n",
    "    pruned_H = []\n",
    "    for conseq in H:\n",
    "        conf = support_data[freqSet] / support_data[freqSet - conseq]\n",
    "        if conf >= min_confidence:\n",
    "            #print (freqSet - conseq, '--->', conseq, 'conf:', conf)\n",
    "            rules.append((freqSet - conseq, conseq, conf))\n",
    "            pruned_H.append(conseq)\n",
    "    return pruned_H\n",
    "\n",
    "\n",
    "def rules_from_conseq(freqSet, H, support_data, rules, min_confidence=0.7):\n",
    "    \"Generate a set of candidate rules\"\n",
    "    m = len(H[0])\n",
    "    if (len(freqSet) > (m + 1)):\n",
    "        Hmp1 = aprioriGen(H, m + 1)\n",
    "        Hmp1 = calc_confidence(freqSet, Hmp1,  support_data, rules, min_confidence)\n",
    "        if len(Hmp1) > 1:\n",
    "            rules_from_conseq(freqSet, Hmp1, support_data, rules, min_confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****Rules\n",
      "(frozenset({'40s'}), frozenset({'clusters1'}), 0.8803952158086323)\n",
      "(frozenset({'DietLow'}), frozenset({'clusters1'}), 0.7212364052661705)\n",
      "(frozenset({'normalweight'}), frozenset({'clusters1'}), 0.7016293279022403)\n",
      "(frozenset({'DietVeryLow'}), frozenset({'clusters1'}), 0.7782426778242678)\n",
      "(frozenset({'sport'}), frozenset({'clusters1'}), 0.8181818181818182)\n",
      "(frozenset({'diabetescomplejo'}), frozenset({'clusters1'}), 0.743086978381096)\n",
      "(frozenset({'diabetes', '40s'}), frozenset({'obese', 'clusters1'}), 0.7142857142857142)\n",
      "(frozenset({'nosport', 'DietVeryLow', 'sano'}), frozenset({'40s', 'clusters1'}), 0.7199999999999999)\n",
      "(frozenset({'diabetescomplejo', '40s', 'normalweight', 'DietAverage'}), frozenset({'nosport', 'clusters1'}), 0.7345132743362831)\n",
      "(frozenset({'nosport', 'diabetescomplejo', 'DietVeryLow', 'overweight'}), frozenset({'40s', 'clusters1'}), 0.787878787878788)\n",
      "(frozenset({'DietHigh', 'clusters0', '40s', 'sano'}), frozenset({'nosport', 'overweight'}), 0.7142857142857142)\n"
     ]
    }
   ],
   "source": [
    "#dataset2=ar1.tolist()\n",
    "dataset=newar_ok\n",
    "\"\"\"\n",
    "#for x in dataset2: print(x)\n",
    "C1=createC1(dataset2)\n",
    "#print(\"C1\",C1)\n",
    "D=map(set,dataset2)\n",
    "L1,support_data=scanD(dataset2,C1,0.5)\n",
    "print(\"L1\",L1)\n",
    "print(\"zeroo\",dataset2[0][0])\n",
    "print(type(dataset2))\n",
    "\n",
    "#out=aprioriGen(L1,2)\n",
    "#print(\"out\",out)\n",
    "#apriori(dataset)\n",
    "#print(\"L\",L)\n",
    "#L,support_data=apriori(dataset,minsupport=0.5)\n",
    "#print(\"L_\",L)\n",
    "\"\"\"\n",
    "L,support_data=apriori(list(dataset),minsupport=0.001)\n",
    "#for z in support_data: print(\"z\",z)\n",
    "#print(\"support_data\",support_data)\n",
    "rules=generateRules(L,support_data,min_confidence=0.7)\n",
    "print(\"****Rules\")\n",
    "for z in rules: \n",
    "    #print(type(z))\n",
    "    #print(z)\n",
    "    if 'cluster' in str(z):\n",
    "        print(z)\n",
    "#print(\"*****Rules: \",rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y 0 1923 230\n",
      "y 1 11 2\n",
      "y 2 19 2\n",
      "y 3 239 53\n",
      "y 4 7 2\n",
      "y 5 113 6\n",
      "y 6 1989 511\n",
      "y 7 33 1\n",
      "y 8 6 0\n",
      "y 9 7 0\n",
      "y 10 31 4\n",
      "y 11 1747 487\n",
      "y 12 63 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "newar_ok=newar.values.tolist()\n",
    "rulesArrived = [0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "rulesOK = [0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "for x in df_3.index:\n",
    "    ruleindex=-1\n",
    "    if ((\"40s\" in newar_ok[x])):\n",
    "        ruleindex=0\n",
    "        rulesArrived[ruleindex]=rulesArrived[ruleindex]+1\n",
    "        if ((\"clusters0\" in newar_ok[x])): rulesOK[ruleindex]=rulesOK[ruleindex]+1\n",
    "    if ((\"sport\" in newar_ok[x])): \n",
    "        ruleindex=1\n",
    "        rulesArrived[ruleindex]=rulesArrived[ruleindex]+1\n",
    "        if ((\"clusters0\" in newar_ok[x])): rulesOK[ruleindex]=rulesOK[ruleindex]+1\n",
    "    if ((\"DietHigh\" in newar_ok[x])and (\"40s\" in newar_ok[x]) and (\"nodiabetes\" in newar_ok[x])and (\"overweight\" in newar_ok[x])): \n",
    "        ruleindex=2\n",
    "        rulesArrived[ruleindex]=rulesArrived[ruleindex]+1\n",
    "        if ((\"nosport\" in newar_ok[x])and (\"clusters0\" in newar_ok[x])): rulesOK[ruleindex]=rulesOK[ruleindex]+1\n",
    "    if ((\"DietVeryLow\" in newar_ok[x])): \n",
    "        ruleindex=3\n",
    "        rulesArrived[ruleindex]=rulesArrived[ruleindex]+1\n",
    "        if ((\"clusters0\" in newar_ok[x])): rulesOK[ruleindex]=rulesOK[ruleindex]+1\n",
    "    if ((\"DietHigh\" in newar_ok[x]) and (\"normalweight\" in newar_ok[x]) and (\"60s\" in newar_ok[x]) and (\"sano\" in newar_ok[x])): \n",
    "        ruleindex=4\n",
    "        rulesArrived[ruleindex]=rulesArrived[ruleindex]+1\n",
    "        if ((\"nosport\" in newar_ok[x]) and (\"clusters1\" in newar_ok[x])): rulesOK[ruleindex]=rulesOK[ruleindex]+1\n",
    "    if ((\"diabetescomplejo\" in newar_ok[x]) and (\"40s\" in newar_ok[x]) and (\"normalweight\" in newar_ok[x]) and (\"DietAverage\" in newar_ok[x])): \n",
    "        ruleindex=5\n",
    "        rulesArrived[ruleindex]=rulesArrived[ruleindex]+1\n",
    "        if ((\"nosport\" in newar_ok[x]) and (\"clusters0\" in newar_ok[x])): rulesOK[ruleindex]=rulesOK[ruleindex]+1\n",
    "    if ((\"diabetescomplejo\" in newar_ok[x])):\n",
    "        ruleindex=6\n",
    "        rulesArrived[ruleindex]=rulesArrived[ruleindex]+1\n",
    "        if ((\"clusters0\" in newar_ok[x])): rulesOK[ruleindex]=rulesOK[ruleindex]+1\n",
    "    if ((\"nosport\" in newar_ok[x]) and (\"diabetescomplejo\" in newar_ok[x]) and (\"DietVeryLow\" in newar_ok[x]) and (\"overweight\" in newar_ok[x])): \n",
    "        ruleindex=7\n",
    "        rulesArrived[ruleindex]=rulesArrived[ruleindex]+1\n",
    "        if ((\"40s\" in newar_ok[x]) and (\"clusters0\" in newar_ok[x])): rulesOK[ruleindex]=rulesOK[ruleindex]+1\n",
    "    if ((\"diabetescomplejo\" in newar_ok[x]) and (\"sport\" in newar_ok[x])):\n",
    "        ruleindex=8\n",
    "        rulesArrived[ruleindex]=rulesArrived[ruleindex]+1\n",
    "        if ((\"40s\" in newar_ok[x])and (\"clusters0\" in newar_ok[x])): rulesOK[ruleindex]=rulesOK[ruleindex]+1\n",
    "    if ((\"diabetes\" in newar_ok[x]) and (\"40s\" in newar_ok[x])):\n",
    "        ruleindex=9\n",
    "        rulesArrived[ruleindex]=rulesArrived[ruleindex]+1\n",
    "        if ((\"clusters0\" in newar_ok[x])and (\"obese\" in newar_ok[x])): rulesOK[ruleindex]=rulesOK[ruleindex]+1\n",
    "    if ((\"DietHigh\" in newar_ok[x]) and (\"diabetescomplejo\" in newar_ok[x]) and (\"40s\" in newar_ok[x]) and (\"normalweight\" in newar_ok[x])): \n",
    "        ruleindex=10\n",
    "        rulesArrived[ruleindex]=rulesArrived[ruleindex]+1\n",
    "        if ((\"nosport\" in newar_ok[x]) and (\"clusters0\" in newar_ok[x])): rulesOK[ruleindex]=rulesOK[ruleindex]+1\n",
    "    if ((\"DietLow\" in newar_ok[x])):\n",
    "        ruleindex=11\n",
    "        rulesArrived[ruleindex]=rulesArrived[ruleindex]+1\n",
    "        if ((\"clusters0\" in newar_ok[x])): rulesOK[ruleindex]=rulesOK[ruleindex]+1\n",
    "    if ((\"diabetescomplejo\" in newar_ok[x]) and (\"DietVeryLow\" in newar_ok[x]) and (\"overweight\" in newar_ok[x])): \n",
    "        ruleindex=12\n",
    "        rulesArrived[ruleindex]=rulesArrived[ruleindex]+1\n",
    "        if ((\"40s\" in newar_ok[x]) and (\"clusters0\" in newar_ok[x])): rulesOK[ruleindex]=rulesOK[ruleindex]+1\n",
    "\n",
    "for y in range(0,13,1):\n",
    "    print(\"y\",y,rulesArrived[y], rulesOK[y])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1130, 354)\n",
      "df_2 (1130, 343)\n",
      "[46 47 48 49 59 60]\n",
      "df_3 (1130, 337)\n",
      "df_4 (1130, 337)\n",
      "data (1130, 337)\n",
      "Num pca_comps per > 0.8 ratio: 44 0.802450643395\n",
      "Explained variance first 2 components 0.146532196687\n",
      "337\n",
      "0.146532196687\n",
      "PCA+K-means: 44\n",
      "[1 0 1 ..., 1 0 0]\n",
      "count 1130\n",
      "newarshape (1130, 6)\n",
      "Fila:      clusters              tipo        weight  age    sport         Diet\n",
      "0  clusters1  diabetescomplejo         obese  40s  nosport  DietAverage\n",
      "1  clusters0  diabetescomplejo  normalweight  40s      NaN  DietAverage\n",
      "** [['clusters1', 'diabetescomplejo', 'obese', '40s', 'nosport', 'DietAverage'], ['clusters0', 'diabetescomplejo', 'normalweight', '40s', 'DietAverage'], ['clusters1', 'nodiabetes', 'overweight', '60s', 'nosport', 'DietAverage'], ['clusters1', 'nodiabetes', 'overweight', '50s', 'DietLow'], ['clusters1', 'diabetescomplejo', 'overweight', '40s', 'nosport', 'DietAverage']]\n",
      "Longitud final:  1130\n",
      "y 0 476 155\n",
      "y 1 3 0\n",
      "y 2 4 0\n",
      "y 3 58 17\n",
      "y 4 0 0\n",
      "y 5 29 8\n",
      "y 6 524 169\n",
      "y 7 4 0\n",
      "y 8 0 0\n",
      "y 9 0 0\n",
      "y 10 12 3\n",
      "y 11 436 108\n",
      "y 12 11 1\n"
     ]
    }
   ],
   "source": [
    "print(df_test.shape)\n",
    "#df_test = df_test.reset_index()\n",
    "# In[112]:\n",
    "\n",
    "to_del = ['entity_id','sampleType','FECHA_NACIMIENTO','MUNICIPIO_RESIDENCIA',\n",
    "          'MUNICIPIO_NACIMIENTO','PROVINCIA_RESIDENCIA','PAIS_NACIMIENTO', 'CALC_AVG_HEIGHT','CALC_AVG_PESO','CALC_AVG_CINTURA','CALC_AVG_CADERA' \n",
    "         ]\n",
    "\"\"\"\n",
    "to_del.extend(['ENFERMEDADES_DIABETES','ENFERMEDADES_HTA',\n",
    "              'ENFERMEDADES_HIPERCOLESTEROLEMIA','ENFERMEDADES_ICTUS',\n",
    "              'ENFERMEDADES_INFARTO','ENFERMEDADES_ANGINA'\n",
    "              ])\n",
    "\"\"\"\n",
    "\n",
    "#Filter_selected cols\n",
    "filtered_cols = [c for c in df_test.columns if (c not in to_del) ]#and ('ENF' not in c)\n",
    "df_2 = df_test[filtered_cols]\n",
    "print (\"df_2\",df_2.shape)\n",
    "\n",
    "# Filter complete null columns\n",
    "cols = np.where((np.sum(df_2.isnull(), axis=0).values) == df_2.shape[0])[0]\n",
    "print (cols)\n",
    "filt_cols = [c for c in df_2.columns if c not in df_2.columns[cols]]\n",
    "df_3 = df_2[filt_cols]\n",
    "print (\"df_3\",df_3.shape)\n",
    "\n",
    "#Fill na\n",
    "df_4 = df_3.fillna(value=np.mean(df_3,axis=0),inplace=False,axis=0).values\n",
    "print (\"df_4\",df_4.shape)\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler().fit(df_4)\n",
    "data = scaler.transform(df_4)\n",
    "data2 = df_4\n",
    "print (\"data\",data.shape)\n",
    "\n",
    "thrd = 0.8\n",
    "total = 0\n",
    "pca = PCA().fit(data)\n",
    "reduced_data = pca.transform(data)\n",
    "for pca_comps,r in enumerate(pca.explained_variance_ratio_):\n",
    "    if total > thrd:\n",
    "        break\n",
    "    total += r\n",
    "print (\"Num pca_comps per >\", thrd,\"ratio:\", pca_comps, total)\n",
    "print (\"Explained variance first 2 components\",pca.explained_variance_ratio_[0]+pca.explained_variance_ratio_[1])\n",
    "print (pca.n_components_)\n",
    "print (np.sum(pca.explained_variance_ratio_[:2]))\n",
    "\n",
    "print (\"PCA+K-means:\", pca_comps)\n",
    "\n",
    "n_clusters = 2\n",
    "pca = PCA().fit(data)\n",
    "\n",
    "\n",
    "reduced_data = pca.transform(data)\n",
    "\n",
    "kmeans.predict(reduced_data[:,:2])\n",
    "print(kmeans.labels_)\n",
    "kmeans.labels_.shape\n",
    "\n",
    "newar = pd.DataFrame()\n",
    "count=0\n",
    "for x in df_3.index: \n",
    "    #print(\"Count\",count)\n",
    "    newar.set_value(count,'clusters','{}{}'.format('clusters',kmeans.labels_[count])) \n",
    "    if (df_test.loc[count,'ENFERMEDADES_DIABETES_T2DM']==0 and df_test.loc[count,'ENFERMEDADES_HIPERCOLESTEROLEMIA']==0 and df_test.loc[count,'ENFERMEDADES_HTA']==0 and df_test.loc[count,'ENFERMEDADES_ICTUS']==0 and df_test.loc[count,'ENFERMEDADES_ANGINA']==0 and df_test.loc[count,'ENFERMEDADES_INFARTO']==0):newar.set_value(count,'tipo','sano')\n",
    "    else:\n",
    "        if (df_test.loc[count,'ENFERMEDADES_DIABETES_T2DM']==0): newar.set_value(count,'tipo','nodiabetes')\n",
    "        else:\n",
    "            if (df_test.loc[count,'ENFERMEDADES_DIABETES_T2DM']==1 and df_test.loc[count,'ENFERMEDADES_HIPERCOLESTEROLEMIA']==0 and df_test.loc[count,'ENFERMEDADES_HTA']==0 and df_test.loc[count,'ENFERMEDADES_ICTUS']==0 and df_test.loc[count,'ENFERMEDADES_ANGINA']==0 and df_test.loc[count,'ENFERMEDADES_INFARTO']==0):newar.set_value(count,'tipo','diabetes')\n",
    "            else:newar.set_value(count,'tipo','diabetescomplejo')\n",
    "    if(df_test.loc[count,'BMI']<18.5): newar.set_value(count,'weight','underweight')\n",
    "    else:\n",
    "        if(df_test.loc[count,'BMI']<24.9): newar.set_value(count,'weight','normalweight')\n",
    "        else:\n",
    "            if (df_test.loc[count,'BMI']<29.9): newar.set_value(count,'weight','overweight')\n",
    "            else:\n",
    "                if (df_test.loc[count,'BMI']>29.8): newar.set_value(count,'weight','obese')\n",
    "    if(df_test.loc[count,'EDAD_ANOS']<50): newar.set_value(count,'age','40s')\n",
    "    else:\n",
    "        if(df_test.loc[count,'EDAD_ANOS']<60): newar.set_value(count,'age','50s')\n",
    "        else:\n",
    "            if (df_test.loc[count,'EDAD_ANOS']<70): newar.set_value(count,'age','60s')\n",
    "    if(df.loc[count,'ACTIVIDAD_FISICA_LIBRE_DEPORTE_REGULAR_0']==1): newar.set_value(count,'sport','sport')\n",
    "    if(df.loc[count,'ACTIVIDAD_FISICA_LIBRE_DEPORTE_REGULAR_1']==1): newar.set_value(count,'sport','nosport')\n",
    "    if(df.loc[count,'PREDIMED_SCORE']<5): newar.set_value(count,'Diet','DietVeryLow')\n",
    "    else:\n",
    "        if(df.loc[count,'PREDIMED_SCORE']<8): newar.set_value(count,'Diet','DietLow')\n",
    "        else:\n",
    "            if (df.loc[count,'PREDIMED_SCORE']<11): newar.set_value(count,'Diet','DietAverage')\n",
    "            else:\n",
    "                newar.set_value(count,'Diet','DietHigh') \n",
    "    count=count+1\n",
    "print(\"count\",count)\n",
    "print(\"newarshape\",newar.shape)\n",
    "print(\"Fila: \",newar.head(2))\n",
    "newar_ok=newar.values.tolist()\n",
    "newar_ok_copy=newar_ok\n",
    "\n",
    "for x in range(len(newar_ok)): \n",
    "    #print(\"X\", x, \",\",newar_ok[x])\n",
    "    astring=newar_ok[x]\n",
    "    y=0\n",
    "    for y in range(len(astring),0,-1):\n",
    "        #print(\"y\",y-1,\":\",astring[y-1])\n",
    "        if(str(astring[y-1]).endswith('nan')):\n",
    "            newar_ok[x].remove(astring[y-1])\n",
    "            #print(\"Removed\",newar_ok[x])\n",
    "    #if(len(newar_ok[x])==1):\n",
    "    #print(\"Final: \", x, \",\",newar_ok[x])\n",
    "\n",
    "        #newar_ok=remove_element(newar_ok,x)\n",
    "    #print(newar_ok[x])    \n",
    "    #if (newar_ok[x].endswith('nan')):\n",
    "        #newar_ok.pop(x)\n",
    "    #print(\"Final2: \", x, \",\",newar_ok[x])\n",
    "    \n",
    "for x in range (len(newar_ok),0,-1):\n",
    "    if(len(newar_ok[x-1])==1):\n",
    "        #print('hola')\n",
    "        del newar_ok[x-1]\n",
    "    \n",
    "print(\"**\",newar_ok[0:5])\n",
    "print(\"Longitud final: \",len(newar_ok))\n",
    "\n",
    "newar_ok=newar.values.tolist()\n",
    "rulesArrived = [0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "rulesOK = [0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "for x in df_3.index:\n",
    "    ruleindex=-1\n",
    "    if ((\"40s\" in newar_ok[x])):\n",
    "        ruleindex=0\n",
    "        rulesArrived[ruleindex]=rulesArrived[ruleindex]+1\n",
    "        if ((\"clusters0\" in newar_ok[x])): rulesOK[ruleindex]=rulesOK[ruleindex]+1\n",
    "    if ((\"sport\" in newar_ok[x])): \n",
    "        ruleindex=1\n",
    "        rulesArrived[ruleindex]=rulesArrived[ruleindex]+1\n",
    "        if ((\"clusters0\" in newar_ok[x])): rulesOK[ruleindex]=rulesOK[ruleindex]+1\n",
    "    if ((\"DietHigh\" in newar_ok[x])and (\"40s\" in newar_ok[x]) and (\"nodiabetes\" in newar_ok[x])and (\"overweight\" in newar_ok[x])): \n",
    "        ruleindex=2\n",
    "        rulesArrived[ruleindex]=rulesArrived[ruleindex]+1\n",
    "        if ((\"nosport\" in newar_ok[x])and (\"clusters0\" in newar_ok[x])): rulesOK[ruleindex]=rulesOK[ruleindex]+1\n",
    "    if ((\"DietVeryLow\" in newar_ok[x])): \n",
    "        ruleindex=3\n",
    "        rulesArrived[ruleindex]=rulesArrived[ruleindex]+1\n",
    "        if ((\"clusters0\" in newar_ok[x])): rulesOK[ruleindex]=rulesOK[ruleindex]+1\n",
    "    if ((\"DietHigh\" in newar_ok[x]) and (\"normalweight\" in newar_ok[x]) and (\"60s\" in newar_ok[x]) and (\"sano\" in newar_ok[x])): \n",
    "        ruleindex=4\n",
    "        rulesArrived[ruleindex]=rulesArrived[ruleindex]+1\n",
    "        if ((\"nosport\" in newar_ok[x]) and (\"clusters1\" in newar_ok[x])): rulesOK[ruleindex]=rulesOK[ruleindex]+1\n",
    "    if ((\"diabetescomplejo\" in newar_ok[x]) and (\"40s\" in newar_ok[x]) and (\"normalweight\" in newar_ok[x]) and (\"DietAverage\" in newar_ok[x])): \n",
    "        ruleindex=5\n",
    "        rulesArrived[ruleindex]=rulesArrived[ruleindex]+1\n",
    "        if ((\"nosport\" in newar_ok[x]) and (\"clusters0\" in newar_ok[x])): rulesOK[ruleindex]=rulesOK[ruleindex]+1\n",
    "    if ((\"diabetescomplejo\" in newar_ok[x])):\n",
    "        ruleindex=6\n",
    "        rulesArrived[ruleindex]=rulesArrived[ruleindex]+1\n",
    "        if ((\"clusters0\" in newar_ok[x])): rulesOK[ruleindex]=rulesOK[ruleindex]+1\n",
    "    if ((\"nosport\" in newar_ok[x]) and (\"diabetescomplejo\" in newar_ok[x]) and (\"DietVeryLow\" in newar_ok[x]) and (\"overweight\" in newar_ok[x])): \n",
    "        ruleindex=7\n",
    "        rulesArrived[ruleindex]=rulesArrived[ruleindex]+1\n",
    "        if ((\"40s\" in newar_ok[x]) and (\"clusters0\" in newar_ok[x])): rulesOK[ruleindex]=rulesOK[ruleindex]+1\n",
    "    if ((\"diabetescomplejo\" in newar_ok[x]) and (\"sport\" in newar_ok[x])):\n",
    "        ruleindex=8\n",
    "        rulesArrived[ruleindex]=rulesArrived[ruleindex]+1\n",
    "        if ((\"40s\" in newar_ok[x])and (\"clusters0\" in newar_ok[x])): rulesOK[ruleindex]=rulesOK[ruleindex]+1\n",
    "    if ((\"diabetes\" in newar_ok[x]) and (\"40s\" in newar_ok[x])):\n",
    "        ruleindex=9\n",
    "        rulesArrived[ruleindex]=rulesArrived[ruleindex]+1\n",
    "        if ((\"clusters0\" in newar_ok[x])and (\"obese\" in newar_ok[x])): rulesOK[ruleindex]=rulesOK[ruleindex]+1\n",
    "    if ((\"DietHigh\" in newar_ok[x]) and (\"diabetescomplejo\" in newar_ok[x]) and (\"40s\" in newar_ok[x]) and (\"normalweight\" in newar_ok[x])): \n",
    "        ruleindex=10\n",
    "        rulesArrived[ruleindex]=rulesArrived[ruleindex]+1\n",
    "        if ((\"nosport\" in newar_ok[x]) and (\"clusters0\" in newar_ok[x])): rulesOK[ruleindex]=rulesOK[ruleindex]+1\n",
    "    if ((\"DietLow\" in newar_ok[x])):\n",
    "        ruleindex=11\n",
    "        rulesArrived[ruleindex]=rulesArrived[ruleindex]+1\n",
    "        if ((\"clusters0\" in newar_ok[x])): rulesOK[ruleindex]=rulesOK[ruleindex]+1\n",
    "    if ((\"diabetescomplejo\" in newar_ok[x]) and (\"DietVeryLow\" in newar_ok[x]) and (\"overweight\" in newar_ok[x])): \n",
    "        ruleindex=12\n",
    "        rulesArrived[ruleindex]=rulesArrived[ruleindex]+1\n",
    "        if ((\"40s\" in newar_ok[x]) and (\"clusters0\" in newar_ok[x])): rulesOK[ruleindex]=rulesOK[ruleindex]+1\n",
    "\n",
    "\n",
    "for y in range(0,13,1):\n",
    "    print(\"y\",y,rulesArrived[y], rulesOK[y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y 0 0.32563025210084034\n",
      "y 1 0.0\n",
      "y 2 0.0\n",
      "y 3 0.29310344827586204\n",
      "y 5 0.27586206896551724\n",
      "y 6 0.32251908396946566\n",
      "y 7 0.0\n",
      "y 10 0.25\n",
      "y 11 0.24770642201834864\n",
      "y 12 0.09090909090909091\n"
     ]
    }
   ],
   "source": [
    "for y in range(0,13,1):\n",
    "    if (rulesArrived[y]!=0):\n",
    "        print(\"y\",y,rulesOK[y]/rulesArrived[y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
